# -*- coding: utf-8 -*-
"""heart_ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10cJYGOMqnnkok6-JRm4nR5312GfWkiRU
"""

import numpy as np
import pandas as pd
df=pd.read_csv("/content/heart.csv")
df

df.isna().sum()

x=df.iloc[:,:-1].values
x

y=df.iloc[:,-1].values
y

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=42)

x_train

y_test

y_train

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
scaler.fit(x_train)


x_train=scaler.fit_transform(x_train)
x_test=scaler.fit_transform(x_test)
x_train



# Initialize ANN
import tensorflow as tf
ann=tf.keras.models.Sequential()

ann.add(tf.keras.layers.Dense(6,activation='relu'))

ann.add(tf.keras.layers.Dense(6,activation='relu'))

ann.add(tf.keras.layers.Dense(6,activation='sigmoid'))

# compiling ANN
ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

x_train.shape

# 
ann.fit(x_train,y_train,batch_size=10,epochs=100)

# summerization
ann.summary()

pred=ann.predict(scaler.transform([[52,1,0,25,12,0,1,68,0,1,2,2,3]]))
pred

